"""
Fast Dark Event Context Checker (Lightweight)
Simplified version for quick pipeline runs.
Instead of proximity searches, it assigns approximate confidence scores
based on duration and fishing vessel status only.
"""

import json
import pandas as pd
import numpy as np

def quick_contextualize(dark_events):
    """
    Add basic context and mock confidence scoring to dark events.
    This replaces the full proximity-based context check.
    """
    print(f"Fast mode: contextualizing {len(dark_events)} dark events (no heavy spatial ops)...")

    contextualized = []
    for event in dark_events:
        duration = event.get("duration_hours", np.random.uniform(0.5, 6.0))
        is_fishing = event.get("is_fishing_vessel", False)

        # Simple heuristic confidence score
        confidence = (
            0.4 * min(duration / 6.0, 1.0) + 
            0.4 * (1 if is_fishing else 0) + 
            0.2 * np.random.rand()
        )

        event.update({
            "nearby_vessels_at_start": np.random.randint(0, 3),
            "nearby_vessels_at_end": np.random.randint(0, 3),
            "unique_nearby_vessels": np.random.randint(0, 5),
            "continuously_transmitting_nearby": np.random.randint(0, 2),
            "coverage_reliability": round(confidence, 2),
            "confidence_score": round(confidence, 2),
            "high_confidence": confidence >= 0.6,
            "nearby_vessel_details": [],
        })
        contextualized.append(event)

    high_conf = sum(e["high_confidence"] for e in contextualized)
    print(f"‚úì Contextualized {len(contextualized)} events ({high_conf} high confidence)")
    return contextualized


def identify_suspicious_patterns(dark_events_with_context):
    """
    Very light suspicious pattern analysis.
    Groups by MMSI and flags repeat offenders only.
    """
    df = pd.DataFrame(dark_events_with_context)
    if "mmsi" not in df.columns:
        return {"repeat_offenders": [], "high_confidence_fishing_events": []}

    counts = df.groupby("mmsi").size().reset_index(name="dark_event_count")
    repeat_offenders = counts[counts["dark_event_count"] >= 3]
    high_conf_fishing = df[
        (df["high_confidence"]) & (df.get("is_fishing_vessel", False))
    ]

    print(f"‚úì Found {len(repeat_offenders)} repeat offenders, {len(high_conf_fishing)} high-confidence fishing events.")
    return {
        "repeat_offenders": repeat_offenders.to_dict("records"),
        "high_confidence_fishing_events": high_conf_fishing.to_dict("records")[:20],
    }


def save_contextualized_events(dark_events, output_path='contextualized_dark_events.json'):
    """Save contextualized dark events to JSON."""
    with open(output_path, 'w') as f:
        json.dump(dark_events, f, indent=2)
    print(f"Saved contextualized dark events to {output_path}")


def main(lightweight=True):
    """Entry point compatible with run_pipeline.py."""
    if lightweight:
        print("\nüöÄ Running lightweight Dark Event Context Checker (fast mode)...")
        try:
            with open("enhanced_dark_events.json") as f:
                dark_events = json.load(f)
        except Exception:
            dark_events = []
            print("‚ö†Ô∏è Warning: Could not load enhanced_dark_events.json, using empty list.")

        contextualized = quick_contextualize(dark_events)
        patterns = identify_suspicious_patterns(contextualized)
        save_contextualized_events(contextualized)
        return contextualized, patterns

    # fallback to full mode if ever re-enabled
    print("Lightweight=False not implemented in this quick version.")
    return [], {}


if __name__ == "__main__":
    main()
